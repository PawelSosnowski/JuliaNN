{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass and gradient calculation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conv2d! (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Conv 2d, assumes square input, filter and stride = 1, no bias\n",
    "function conv2d_layer(input, filters)\n",
    "    f_dim, in_channels, out_channels = size(filters)[2:4]\n",
    "    i_dim = size(input)[2]\n",
    "    out_dim = i_dim - f_dim + 1\n",
    "\n",
    "    output = zeros(out_dim, out_dim, out_channels)\n",
    "    \n",
    "    for n in 1:out_channels\n",
    "        for c in 1:in_channels\n",
    "            conv2d!(@view(output[:, :, n]), input[:, :, c], filters[:,:, c, n], f_dim, out_dim)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return output\n",
    "end\n",
    "\n",
    "\n",
    "function conv2d!(output, input, filter, f_dim, out_dim)\n",
    "    for i in 1:out_dim\n",
    "        for j in 1:out_dim\n",
    "            output[i, j] += sum(input[i:i+f_dim-1, j:j+f_dim-1] .* filter)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relu (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# relu\n",
    "function relu(input)\n",
    "    return max.(0, input)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maxpool2d (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# maxpool2d, assumes kernel_size == stride\n",
    "\n",
    "function maxpool2d(input, kernel_size)\n",
    "    dim_i, n_filters = size(input)[2:3]\n",
    "    out_dim = floor(Int, dim_i / kernel_size)\n",
    "    output = Array{Float32, 3}(undef, out_dim, out_dim, n_filters)\n",
    "    indices = zero(input)\n",
    "\n",
    "    for n in 1:n_filters\n",
    "        for i in 1:out_dim\n",
    "            for j in 1:out_dim\n",
    "                input_fragment = input[(i-1)*kernel_size+1:i*kernel_size, (j-1)*kernel_size+1:j*kernel_size, n]\n",
    "                max_x, max_y = Tuple(argmax(input_fragment))\n",
    "                max_x += (i-1)*kernel_size\n",
    "                max_y += (j-1)*kernel_size\n",
    "                indices[max_x, max_y, n] = 1\n",
    "                output[i, j, n] = input[max_x, max_y, n]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return output, indices\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flatten (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# flatten\n",
    "function flatten(input)\n",
    "    return reshape(input, prod(size(input)), 1)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linear (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fully connected (linear)\n",
    "function linear(input, weights, bias)\n",
    "        # output = Array{Float32, 2}(undef, size(weights)[1], size(input)[2])\n",
    "    return weights * input + bias\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_softmax (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log softmax using LSE trick\n",
    "function log_softmax(input)\n",
    "    c = maximum(input)\n",
    "    return input .- (c + log(sum(exp.(input .- c))))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nll_loss (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nll_loss, format equivalent to torch.nn.NLLLoss\n",
    "function nll_loss(y, y_true)\n",
    "    for i in 1:size(y)[1]\n",
    "        if y_true[i] == 1.0\n",
    "            return -y[i]\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nll_loss_grad (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# nll_loss grad\n",
    "function nll_loss_grad(y_true)\n",
    "    grad = zero(y_true)\n",
    "    grad[y_true .== 1.0] .= -1.0\n",
    "    return grad\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "log_softmax_grad (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# log_softmax grad\n",
    "function log_softmax_grad(input, grad)\n",
    "    grad = exp.(input) / sum(exp.(input)) .+ grad\n",
    "    return grad\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linear_grad (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# linear grad\n",
    "function linear_grad(weights, bias, input, grad)\n",
    "    weights_grad = grad * input'\n",
    "    bias_grad = grad\n",
    "    input_grad = weights' * grad\n",
    "    return input_grad, weights_grad, bias_grad\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "flatten_grad (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# flatten grad\n",
    "function flatten_grad(original_input_shape, grad)\n",
    "    return reshape(grad, original_input_shape)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "maxpool2d_grad (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# maxpool2d grad\n",
    "function maxpool2d_grad(indices, kernel_size, grad)\n",
    "    output = copy(indices)\n",
    "    dim_i, n_filters = size(indices)[2:3]\n",
    "    idx_range = floor(Int, dim_i / kernel_size)\n",
    "\n",
    "    for n in 1:n_filters\n",
    "        for i in 1:idx_range\n",
    "            for j in 1:idx_range\n",
    "                output[(i-1)*kernel_size+1:i*kernel_size, (j-1)*kernel_size+1:j*kernel_size, n] .*= grad[i, j, n]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    return output\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relu_grad (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# relu grad\n",
    "function relu_grad(input, grad)\n",
    "    negative_mask = input .<= 0.0\n",
    "    grad[negative_mask] .= 0.0\n",
    "    return grad\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conv2d_layer_grad (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# conv2d grad\n",
    "function conv2d_layer_grad(input, filters, grad)\n",
    "    i_dim = size(input)[2]\n",
    "    grad_dim = size(grad)[2]\n",
    "    f_dim, in_channels, out_channels = size(filters)[2:4]\n",
    "    \n",
    "    padded_dim = size(input)[2] + f_dim - 1\n",
    "\n",
    "    weights_grad = zeros(f_dim, f_dim, in_channels, out_channels)\n",
    "    input_grad = zeros(i_dim, i_dim, in_channels)\n",
    "\n",
    "    for n in out_channels\n",
    "        padded_grad = zeros(padded_dim, padded_dim)\n",
    "        padded_grad[f_dim: end - f_dim + 1, f_dim: end - f_dim + 1] = grad[:, :, n]\n",
    "\n",
    "        for c in in_channels\n",
    "            conv2d!(@view(input_grad[:, :, c]), padded_grad, reverse(filters[:, :, c, n]), f_dim, i_dim) # reverse(filters) (conv) padded(grad)\n",
    "            conv2d!(@view(weights_grad[:, :, c, n]), input[:, :, c], grad[:, :, n], grad_dim, f_dim) # input (conv) grad\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return input_grad, weights_grad\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = ones(28,28,1)\n",
    "input[2,:,1] = input[2,:,1] * 5\n",
    "filters1 = ones(3,3, 1, 32) .* 2 # filters format: (kernel_dim_1, kernel_dim_2, in_channel, out_channel) \n",
    "filters2 = ones(3,3, 32, 64) .* 2; # filters format: (kernel_dim_1, kernel_dim_2, in_channel, out_channel) \n",
    "linear_weights = ones(10, 1600) .* 0.5 # weights format: (out_dim, in_dim)\n",
    "linear_bias = ones(10) .* 2;\n",
    "\n",
    "label = Array{Float32, 2}(undef, 10, 1)\n",
    "label *= 0\n",
    "label[5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# forward pass of network\n",
    "x1 = conv2d_layer(input, filters1)\n",
    "x2 = relu(x1)\n",
    "x3, indices_mp1 = maxpool2d(x1, 2)\n",
    "x4 = conv2d_layer(x3, filters2)\n",
    "x5 = relu(x4)\n",
    "x6, indices_mp2 = maxpool2d(x5, 2)\n",
    "x7 = flatten(x6)\n",
    "x8 = linear(x7, linear_weights, linear_bias)\n",
    "preds = log_softmax(x8)\n",
    "loss = nll_loss(preds, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 101 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m25.129 ms\u001b[22m\u001b[39m … \u001b[35m83.533 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m3.88% … 4.47%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m44.275 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m3.72%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m49.795 ms\u001b[22m\u001b[39m ± \u001b[32m19.193 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m3.42% ± 1.70%\n",
       "\n",
       "  \u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[34m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▅\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m█\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m█\u001b[39m▃\u001b[39m▃\u001b[39m▆\u001b[39m▅\u001b[39m█\u001b[39m▆\u001b[39m▃\u001b[39m▃\u001b[34m▅\u001b[39m\u001b[39m▅\u001b[39m▅\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[32m▃\u001b[39m\u001b[39m▃\u001b[39m▃\u001b[39m▆\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m▆\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▃\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▃\u001b[39m▆\u001b[39m▃\u001b[39m▆\u001b[39m▅\u001b[39m█\u001b[39m▅\u001b[39m▅\u001b[39m▁\u001b[39m▃\u001b[39m▃\u001b[39m \u001b[39m▃\n",
       "  25.1 ms\u001b[90m         Histogram: frequency by time\u001b[39m        82.5 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m61.46 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m550070\u001b[39m."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@benchmark forward(input, filters1, filters2, linear_weights, linear_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28, 1), (26, 26, 32), (26, 26, 32), (13, 13, 32), (11, 11, 64), (11, 11, 64), (5, 5, 64), (1600, 1), (10, 1))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "size(input), size(x1), size(x2), size(x3), size(x4), size(x5), size(x6), size(x7), size(x8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.1102230246251565e-16 1.1102230246251565e-16 … 0.0 0.0; 1.1102230246251565e-16 1.1102230246251565e-16 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;], [0.0 0.0 0.0; 0.0 0.0 0.0; 0.0 0.0 0.0;;;; 0.0 0.0 0.0; 0.0 0.0 0.0; 0.0 0.0 0.0;;;; 0.0 0.0 0.0; 0.0 0.0 0.0; 0.0 0.0 0.0;;;; … ;;;; 0.0 0.0 0.0; 0.0 0.0 0.0; 0.0 0.0 0.0;;;; 0.0 0.0 0.0; 0.0 0.0 0.0; 0.0 0.0 0.0;;;; 1.2490009027033011e-14 1.2490009027033011e-14 1.2490009027033011e-14; 1.582067810090848e-14 1.582067810090848e-14 1.582067810090848e-14; 1.2490009027033011e-14 1.2490009027033011e-14 1.2490009027033011e-14])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# backward pass of network\n",
    "ig, wg, bg = linear_grad(linear_weights, linear_bias, x7, log_softmax_grad(preds, nll_loss_grad(label)))\n",
    "ig = flatten_grad(size(x6), ig)\n",
    "ig = maxpool2d_grad(indices_mp2, 2, ig)\n",
    "ig = relu_grad(x4, ig)\n",
    "ig, fg = conv2d_layer_grad(x3, filters2, ig)\n",
    "ig = maxpool2d_grad(indices_mp1, 2, ig)\n",
    "ig = relu_grad(x1, ig)\n",
    "ig, fg = conv2d_layer_grad(input, filters1, ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Computational graph:\n",
       "(\n",
       "Convolution2D(:input_size, 28)(:kernel_size, 3)(:in_filters, 1)(:out_filters, 32)(:input_shape, (28, 28, 1))\n",
       "         ↓         \n",
       "RELU(:input_shape, (26, 26, 32))\n",
       "         ↓         \n",
       "MaxPool2D(:kernel_size, 2)(:input_shape, (26, 26, 32))\n",
       "         ↓         \n",
       "Convolution2D(:input_size, 13)(:kernel_size, 3)(:in_filters, 32)(:out_filters, 64)(:input_shape, (13, 13, 32))\n",
       "         ↓         \n",
       "RELU(:input_shape, (11, 11, 64))\n",
       "         ↓         \n",
       "MaxPool2D(:kernel_size, 2)(:input_shape, (11, 11, 64))\n",
       "         ↓         \n",
       "Flatten(:input_shape, (5, 5, 64))\n",
       "         ↓         \n",
       "Linear(:input_neurons, 1600)(:output_neurons, 10)(:input_shape, (1600, 1))\n",
       "         ↓         \n",
       "LogSoftmax(:input_shape, (10, 1))\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"nn.jl\")\n",
    "\n",
    "model_dims = [\n",
    "    (28, 28, 1), \n",
    "    (26, 26, 32), \n",
    "    (26, 26, 32), \n",
    "    (13, 13, 32), \n",
    "    (11, 11, 64), \n",
    "    (11, 11, 64), \n",
    "    (5, 5, 64), \n",
    "    (1600, 1), \n",
    "    (10, 1)\n",
    "]\n",
    "\n",
    "model = NNGraph([\n",
    "    Convolution2D(28, 3, 1, 32, model_dims[1]),\n",
    "    RELU(model_dims[2]),\n",
    "    MaxPool2D(2, model_dims[3]),\n",
    "    Convolution2D(13, 3, 32, 64, model_dims[4]),\n",
    "    RELU(model_dims[5]),\n",
    "    MaxPool2D(2, model_dims[6]),\n",
    "    Flatten(model_dims[7]),\n",
    "    Linear(1600, 10, model_dims[8]),\n",
    "    LogSoftmax(model_dims[9])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolution2D"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(:input_size, 28)(:kernel_size, 3)(:in_filters, 1)(:out_filters, 32)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(:input_shape, (28, 28, 1))"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ForwardRELU(:input_shape, (26, 26, 32))"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ForwardMaxPool2D(:kernel_size, 2)(:input_shape, (26, 26, 32))\n",
      "ForwardConvolution2D(:input_size, 13)(:kernel_size, 3)(:in_filters, 32)(:out_filters, 64)(:input_shape, (13, 13, 32))\n",
      "ForwardRELU(:input_shape, (11, 11, 64))\n",
      "ForwardMaxPool2D(:kernel_size, 2)(:input_shape, (11, 11, 64))\n",
      "Forward"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flatten(:input_shape, (5, 5, 64))\n",
      "ForwardLinear(:input_neurons, 1600)(:output_neurons, 10"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")(:input_shape, (1600, 1))"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ForwardLogSoftmax(:input_shape, (10, 1))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "28×28×1 Array{Float32, 3}:\n",
       "[:, :, 1] =\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " ⋮                        ⋮              ⋱                      ⋮         \n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  …  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       " 1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0     1.0  1.0  1.0  1.0  1.0  1.0  1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "forward(Float32.(ones(28,28,1)), model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
